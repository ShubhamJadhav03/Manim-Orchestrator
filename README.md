# ğŸ¨ Manim AI â€” Text-to-Animation Video Generator

<div align="center">

> **An AI-powered platform that transforms text prompts into dynamic 2D animations â€” built with Manim, FastAPI, React, and Ollama.**

[![Docker](https://img.shields.io/badge/Docker-Ready-blue?logo=docker)](https://www.docker.com/)
[![FastAPI](https://img.shields.io/badge/Backend-FastAPI-009688?logo=fastapi)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/Frontend-React-61DAFB?logo=react)](https://reactjs.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

</div>

---

## ğŸŒŸ Overview

**Manim AI** is a **full-stack web application** that generates stunning 2D animations directly from text prompts.  
It uses an **AI model (CodeLlama)** to produce Python code for the [Manim Engine](https://www.manim.community/) â€” bringing ideas to life as animated scenes.

The project includes a **3-panel scene editor** that allows users to preview, rearrange, and export multi-scene videos â€” all in a browser.



https://github.com/user-attachments/assets/527d7ac1-3cb2-4e1d-9298-41d8bf15ce78



---

## âœ¨ Key Features

| Category | Description |
|-----------|--------------|
| ğŸ¤– **AI-Generated Animations** | Converts text prompts into executable Manim scripts using **CodeLlama** via **Ollama**. |
| ğŸ¬ **3-Panel Scene Editor** | Built with React + Tailwind â€” includes Scene Bin, Drag-and-Drop Timeline, and Live Preview. |
| ğŸï¸ **Smart Video Stitching** | Combines multiple scenes into one polished `.mp4` file using **FFmpeg**. |
| âš™ï¸ **Scalable Backend** | Asynchronous FastAPI server with **Celery** workers for non-blocking video jobs. |
| ğŸ³ **One-Command Setup** | Entire stack runs in **Docker** â€” Frontend, Backend, Worker, Redis, PostgreSQL. |
| âœ… **CI/CD Ready** | Includes **GitHub Actions** + **Pytest** for automated backend testing. |

---

## ğŸ§© System Architecture

The application follows a **modern, microservices-oriented design**, ensuring scalability and fault isolation.

![Manim ai](https://github.com/user-attachments/assets/0ef24f06-4f4f-4c83-a8e1-51aecb48aa6f)


### ğŸ§  Workflow Summary
1. The **React frontend** sends the userâ€™s prompt to the **FastAPI backend**.  
2. FastAPI logs the task in **PostgreSQL** and enqueues it in **Redis**.  
3. A **Celery worker** pulls the job, calls **Ollama â†’ CodeLlama**, and runs **Manim** to render the animation.  
4. The worker updates the database with progress and file paths.  
5. The frontend polls for updates and previews the generated scene when ready.


## ğŸ› ï¸ Tech Stack

| Layer | Technologies |
|-------|---------------|
| **Frontend** | `React`, `Tailwind CSS`, `@dnd-kit` (drag-and-drop) |
| **Backend** | `Python`, `FastAPI`, `SQLAlchemy`, `Celery`, `Redis`, `PostgreSQL` |
| **AI Engine** | `Ollama` (local LLM runtime) with `CodeLlama:7b` |
| **Animation** | `Manim` for 2D rendering, `FFmpeg` for stitching |
| **DevOps / CI** | `Docker`, `Docker Compose`, `GitHub Actions`, `Pytest` |

---

## âš¡ Getting Started (Local Setup)

The app is **fully containerized**, so you can spin it up with one command.

### ğŸ§° Prerequisites

Make sure you have:
- [Docker Desktop](https://www.docker.com/products/docker-desktop/) installed & running  
- [Ollama](https://ollama.com/) installed and the model pulled:

  ```bash
  ollama pull codellama:7b
  ```

---

### ğŸš€ Installation & Setup

1. **Clone this repository**
   ```bash
   git clone https://github.com/ShubhamJadhav03/Cursor-For--2D-Videos.git
   cd Cursor-For--2D-Videos
   ```

2. **Build & start all services**
   ```bash
   docker-compose up --build
   ```
   > This command launches the Frontend, Backend, Worker, Redis, and PostgreSQL services simultaneously.

3. **Access the app**
   - ğŸŒ Frontend: [http://localhost:3000](http://localhost:3000)  
   - âš™ï¸ API Docs: [http://localhost:8000/docs](http://localhost:8000/docs)

4. **Shut down all services**
   ```bash
   Ctrl + C
   ```
   Or use:
   ```bash
   docker-compose down
   ```

---

## ğŸ§­ Project Structure

```
Cursor-For--2D-Videos/
â”‚
â”œâ”€â”€ frontend/                # React UI with drag-and-drop scene editor
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI entrypoint
â”‚   â”œâ”€â”€ generation.py        # AI â†’ Manim code logic
â”‚   â”œâ”€â”€ worker.py            # Celery worker for background jobs
â”‚   â”œâ”€â”€ config.py            # Database & environment configuration
â”‚   â””â”€â”€ models.py            # SQLAlchemy ORM models
â”‚
â”œâ”€â”€ docker-compose.yml       # Container orchestration
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ package.json             # Frontend dependencies
â””â”€â”€ README.md
```

---

## ğŸ”® Future Enhancements

| Feature | Description |
|----------|--------------|
| â˜ï¸ **Cloud Deployment** | Deploy stack to **Render**, **AWS**, or **Azure**. |
| ğŸ—£ï¸ **AI Voiceovers** | Add **Text-to-Speech** narration with lip-sync support. |
| ğŸ‘¤ **User Accounts** | Add authentication + project management dashboard. |
| ğŸ¨ **Custom Themes** | Enable users to modify Manim colors, fonts, or styles dynamically. |
| ğŸ“ˆ **Job Analytics** | Track render times, prompt complexity, and system metrics. |

---

## ğŸ’¡ Inspiration & Learning

This project represents a deep dive into:
- Asynchronous job handling with **Celery + Redis**
- End-to-end AI workflow integration with **Ollama**
- Real-time UI feedback with **React hooks**
- Complex system orchestration using **Docker Compose**

> Itâ€™s more than a project â€” itâ€™s a demonstration of full-stack AI engineering skills, from low-level system design to UX polish.

---

## ğŸ§‘â€ğŸ’» Author

**Shubham Jadhav**  
ğŸš€ *AI & Full-Stack Developer*  
ğŸ“ Passionate about creating intelligent and scalable web systems.  

[![GitHub](https://img.shields.io/badge/GitHub-ShubhamJadhav03-black?logo=github)](https://github.com/ShubhamJadhav03)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-ShubhamJadhav-blue?logo=linkedin)](https://www.linkedin.com/in/shubham-jadhav-3058a42a7/)

---

## ğŸªª License

This project is licensed under the **MIT License** â€” feel free to use, modify, and distribute it with attribution.

